{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import lru_cache as memoize\n",
    "from os.path import join as join_path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from nltk.corpus import wordnet as wn\n",
    "from PyDictionary import PyDictionary\n",
    "DICTIONARY = PyDictionary()\n",
    "\n",
    "OUTPUT_DIR = '../../data/output/trial_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this is a temperary function for txt searching. Change this if using sqlite\n",
    "def search_file(filename, string):\n",
    "    \"\"\"search specific string in file\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        results = {}\n",
    "        for line in f.readlines():\n",
    "            ls = line.split()\n",
    "            if string == ls[0]:\n",
    "                results[ls[1]] = float(ls[2])\n",
    "    return results\n",
    "\n",
    "\n",
    "@memoize(maxsize=None)\n",
    "def get_synonyms(word, pos=None):\n",
    "    \"\"\"Get synonyms for a word using PyDictionary and WordNet.\n",
    "\n",
    "    Arguments:\n",
    "        word (str): The word to find synonyms for.\n",
    "        pos (int): WordNet part-of-speech constant. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        set[str]: The set of synonyms.\n",
    "    \"\"\"\n",
    "    syn_list = []\n",
    "\n",
    "    # add WordNet synonyms to the list\n",
    "    for synset in wn.synsets(word, pos):\n",
    "        for lemma in synset.lemmas():\n",
    "            syn = lemma.name()\n",
    "            if syn != word:\n",
    "                syn_list.append(syn)\n",
    "    # add thesaurus synonyms\n",
    "    dict_syns = DICTIONARY.synonym(word)\n",
    "\n",
    "    # combine them and return\n",
    "    if dict_syns:\n",
    "        return set(syn_list) | set(dict_syns)\n",
    "    else:\n",
    "        return set(syn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_words(word, word_pos, expect_pos):\n",
    "    \"\"\"\n",
    "    this function return the given word's all verb/noun/adj and it's probability\n",
    "    Args:\n",
    "        word: a given word\n",
    "        word_pos: the given word's part of speech\n",
    "        expect_pos: expected words' part of speech\n",
    "\n",
    "    Returns:\n",
    "        (dictionary) {related word: probability}\n",
    "    \"\"\"\n",
    "    filename = join_path(OUTPUT_DIR, (\"prob_\" + expect_pos + \"_\" + word_pos + \".txt\"))\n",
    "    return search_file(filename, word)\n",
    "\n",
    "\n",
    "def get_wn_pos(pos):\n",
    "    \"\"\"untility function that return wordnet's part of speech parameter for given pos\"\"\"\n",
    "    if pos == \"noun\":\n",
    "        return wn.NOUN\n",
    "    elif pos == \"verb\":\n",
    "        return wn.VERB\n",
    "    elif pos == \"adj\":\n",
    "        return wn.ADJ\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_synonyms_dict(word, word_pos, expect_pos):\n",
    "    \"\"\"\n",
    "    find the given word's synonym's related expect_pos word and their probability\n",
    "    Args:\n",
    "        word (str): the word querying for it's synonym\n",
    "        word_pos (str): the part of speech of the given word\n",
    "        expect_pos (str): the part of speech of the expected \n",
    "    Returns:\n",
    "        word_dict (dictionary): {word: {expect: prob}}\n",
    "        syn_dict (dictionary): {synonym: {expect: prob}}\n",
    "    \"\"\"\n",
    "    syn_dict = {}\n",
    "    word_dict = {word:{}}\n",
    "    syn_list = list(get_synonyms(word, get_wn_pos(word_pos)))\n",
    "    word_dict[word] = get_related_words(word, word_pos, expect_pos)\n",
    "    for synonym in syn_list:\n",
    "        syn_dict[synonym] = get_related_words(synonym, word_pos, expect_pos)\n",
    "    return word_dict, syn_dict\n",
    "\n",
    "    \n",
    "def get_synonym_df (word, word_pos, expect_pos, save=0):\n",
    "    \"\"\"\n",
    "    return a dataframe with the given word's synonym's related expect_pos word and their probability\n",
    "    Args:\n",
    "        word (str): the word querying for it's synonym\n",
    "        word_pos (str): the part of speech of the given word\n",
    "        expect_pos (str): the part of speech of the expected \n",
    "    Returns:\n",
    "        (dataframe)\n",
    "    \"\"\"\n",
    "    word_dict, syn_dict = get_synonyms_dict(word, word_pos, expect_pos)\n",
    "    columns = [key for key in word_dict]\n",
    "    columns.extend([synonym for synonym in syn_dict])\n",
    "\n",
    "    word_df = pd.DataFrame.from_dict(word_dict)\n",
    "    syn_df = pd.DataFrame.from_dict(syn_dict)\n",
    "    df = pd.concat([word_df, syn_df], axis=1, join='outer').sort_values(by=[word], ascending=0).fillna(0)\n",
    "    \n",
    "    if save:\n",
    "        file_name = join_path(OUTPUT_DIR, \"syn_test_output\",  (word + \"_\" + word_pos + \"_\" + expect_pos + \".csv\"))\n",
    "        df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "def get_HC(dataframe):\n",
    "    X = dataframe.transpose()\n",
    "    M = linkage(X, method='ward')\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    dn = dendrogram(M, labels=X.index)\n",
    "    plt.show()\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_ls= [\"car\", \"knife\", \"pen\", \"key\", \"bottle\", \"wall\", \"glass\"]\n",
    "for noun in noun_ls:\n",
    "    get_synonym_df(noun, word_pos=\"noun\", expect_pos=\"adj\", save=1)\n",
    "    get_synonym_df(noun, word_pos=\"noun\", expect_pos=\"verb\", save=1)\n",
    "    \n",
    "verb_ls = [\"open\", \"open_with\" \"break\", \"kill\", \"cut\", \"drink_from\"]\n",
    "for verb in verb_ls:\n",
    "    get_synonym_df(verb, word_pos=\"verb\", expect_pos=\"noun\", save=1)\n",
    "\n",
    "adj_ls = [\"sharp\", \"delicious\", \"firm\", \"open\"]\n",
    "for adj in adj_ls:\n",
    "    get_synonym_df(adj, word_pos=\"adj\", expect_pos=\"noun\", save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_synonym_df(\"open\", word_pos=\"verb\", expect_pos=\"noun\", save=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
