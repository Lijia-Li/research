{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import lru_cache as memoize\n",
    "from os.path import join as join_path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from PyDictionary import PyDictionary\n",
    "DICTIONARY = PyDictionary()\n",
    "\n",
    "OUTPUT_DIR = '../../data/output/trial_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this is a temperary function for txt searching. Change this if using sqlite\n",
    "def search_file(filename, string):\n",
    "    \"\"\"search specific string in file\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        results = {}\n",
    "        for line in f.readlines():\n",
    "            ls = line.split()\n",
    "            if string == ls[0]:\n",
    "                results[ls[1]] = float(ls[2])\n",
    "    return results\n",
    "\n",
    "\n",
    "@memoize(maxsize=None)\n",
    "def get_synonyms(word, pos=None):\n",
    "    \"\"\"Get synonyms for a word using PyDictionary and WordNet.\n",
    "\n",
    "    Arguments:\n",
    "        word (str): The word to find synonyms for.\n",
    "        pos (int): WordNet part-of-speech constant. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        set[str]: The set of synonyms.\n",
    "    \"\"\"\n",
    "    syn_list = []\n",
    "\n",
    "    # add WordNet synonyms to the list\n",
    "    for synset in wn.synsets(word, pos):\n",
    "        for lemma in synset.lemmas():\n",
    "            syn = lemma.name()\n",
    "            if syn != word:\n",
    "                syn_list.append(syn)\n",
    "    # add thesaurus synonyms\n",
    "    dict_syns = DICTIONARY.synonym(word)\n",
    "    print(syn_list)\n",
    "\n",
    "    # combine them and return\n",
    "    if dict_syns:\n",
    "        return set(syn_list) | set(dict_syns)\n",
    "    else:\n",
    "        return set(syn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_words(word, word_pos, expect_pos):\n",
    "    \"\"\"\n",
    "    this function return the given word's all verb/noun/adj and it's probability\n",
    "    Args:\n",
    "        word: a given word\n",
    "        word_pos: the given word's part of speech\n",
    "        expect_pos: expected words' part of speech\n",
    "\n",
    "    Returns:\n",
    "        (dictionary) {related word: probability}\n",
    "    \"\"\"\n",
    "    filename = join_path(OUTPUT_DIR, (\"prob_\" + expect_pos + \"_\" + word_pos + \".txt\"))\n",
    "    return search_file(filename, word)\n",
    "\n",
    "\n",
    "def get_wn_pos(pos):\n",
    "    \"\"\"untility function that return wordnet's part of speech parameter for given pos\"\"\"\n",
    "    if pos == \"noun\":\n",
    "        return wn.NOUN\n",
    "    elif pos == \"verb\":\n",
    "        return wn.VERB\n",
    "    elif pos == \"adj\":\n",
    "        return wn.ADJ\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_synonyms_dict(word, word_pos, expect_pos):\n",
    "    \"\"\"\n",
    "    find the given word's synonym's related expect_pos word and their probability\n",
    "    Args:\n",
    "        word (str): the word querying for it's synonym\n",
    "        word_pos (str): the part of speech of the given word\n",
    "        expect_pos (str): the part of speech of the expected \n",
    "    Returns:\n",
    "        word_dict (dictionary): {word: {expect: prob}}\n",
    "        syn_dict (dictionary): {synonym: {expect: prob}}\n",
    "    \"\"\"\n",
    "    syn_dict = {}\n",
    "    word_dict = {word:{}}\n",
    "    syn_list = list(get_synonyms(word, get_wn_pos(word_pos)))\n",
    "    word_dict[word] = get_related_words(word, word_pos, expect_pos)\n",
    "    for synonym in syn_list:\n",
    "        syn_dict[synonym] = get_related_words(synonym, word_pos, expect_pos)\n",
    "    return word_dict, syn_dict\n",
    "\n",
    "    \n",
    "def get_synonym_df (word, word_pos, expect_pos, save=0):\n",
    "    \"\"\"\n",
    "    return a dataframe with the given word's synonym's related expect_pos word and their probability\n",
    "    Args:\n",
    "        word (str): the word querying for it's synonym\n",
    "        word_pos (str): the part of speech of the given word\n",
    "        expect_pos (str): the part of speech of the expected \n",
    "    Returns:\n",
    "        (dataframe)\n",
    "    \"\"\"\n",
    "    word_dict, syn_dict = get_synonyms_dict(word, word_pos, expect_pos)\n",
    "    columns = [key for key in word_dict]\n",
    "    columns.extend([synonym for synonym in syn_dict])\n",
    "\n",
    "    word_df = pd.DataFrame.from_dict(word_dict)\n",
    "    syn_df = pd.DataFrame.from_dict(syn_dict)\n",
    "    df = pd.concat([word_df, syn_df], axis=1, join='outer').sort_values(by=[word], ascending=0)\n",
    "    \n",
    "#     if save:\n",
    "#         file_name = join_path(OUTPUT_DIR, (word + \"_\" + word_pos + \"_\" + expect_pos + \".csv\"))\n",
    "#         print(file_name)       \n",
    "#         df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dict_to_df(\"car\", word_pos=\"noun\", expect_pos=\"adj\", save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook, figure, show\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "from bokeh.models import FactorRange\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[:10].fillna(0)\n",
    "fig = figure(plot_width=400, plot_height=400)\n",
    "x = [(adj, noun) for noun in result.columns for adj in result.index]\n",
    "counts = sum(zip(result['cake'], result['bar'], result['patty']), ())\n",
    "source = ColumnDataSource(data=dict(x=x, counts=counts))\n",
    "fig = figure(x_range=FactorRange(*x), plot_height=250, title=\"Fruit Counts by Year\",\n",
    "           toolbar_location=None, tools=\"\")\n",
    "fig.vbar(x='x', top='counts', width=0.2, source=source)\n",
    "\n",
    "p.y_range.start = 0\n",
    "p.x_range.range_padding = 0.1\n",
    "p.xaxis.major_label_orientation = 0\n",
    "p.xgrid.grid_line_color = None\n",
    "\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
